{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7F2IGaPZF8o",
        "colab_type": "text"
      },
      "source": [
        "# AutoKeras Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnVpu9lqZUvH",
        "colab_type": "text"
      },
      "source": [
        "In this tutorial, the use of AutoKeras will be explained for an example dataset: MNIST. Ofcourse, all the functionalities directly apply on real-life data. Before you start, it is important to note that for the current AutoKeras version 0.4, a Linux system working with Python 3.6 is needed for this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qY52fgLjZONg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! python --version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZM8NZ8xzZ59-",
        "colab_type": "text"
      },
      "source": [
        "For the setup, we will import the needed packages and the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJtZq5SzaBJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip3 install autokeras --no-cache-dir  # install the autokeras package: this is quite big and we try to avoid memory issues I got in the past"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vlUl8RtaMaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import autokeras   # as a test\n",
        "from autokeras.image.image_supervised import load_image_dataset\n",
        "import cv2\n",
        "import sklearn\n",
        "from autokeras.image.image_supervised import ImageClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNXO9hvnaQld",
        "colab_type": "text"
      },
      "source": [
        "# The MNIST example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbPMzgSlaSzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from autokeras.image.image_supervised import ImageClassifier\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()    # download the data\n",
        "x_train = x_train.reshape(x_train.shape + (1,))\n",
        "x_test = x_test.reshape(x_test.shape + (1,))         # A 4D vector is expected"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWixLBeladv7",
        "colab_type": "text"
      },
      "source": [
        "Lets initiate our classifier! We will take one hour of training which should normally be enough for 1GPU to get a good result. Of course for MNIST this works very well but for real-world data, you might need to search longer. As you will see, the logs printed in verbose mode will allow you to follow the process quite nicely. At first, the API will receive the call and preprocesses the dataset. From then on your CPU will be looking for new models based on network morphism guided by Bayesian optimization. Meanwhile, your GPU will be training those in order to find the best performing one. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nqBSh8P7vQG",
        "colab_type": "text"
      },
      "source": [
        "NOTE THAT IF YOU ARE NOT RUNNING ON A GPU, THE SEARCH TIME WILL BE TOO SHORT TO FIND A MODEL (in Google collab you can change this in the settings)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXl-GwMmad3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = ImageClassifier(path=\"mnist_automodels/\", verbose=True)    # declare your classifier, with a path to save it's found models\n",
        "clf.fit(x_train, y_train, time_limit=1 * 60 * 60)    # we will be training for one hour"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQMc5T2Ubv2E",
        "colab_type": "text"
      },
      "source": [
        "Once we reached our time limit or the training converged, we are ready to train our best found model further for best performance. Since it will now include validation data in its training set, we can choose to restart training the weights from scratch with this little more data. This takes a long time, so in this example we will just keep training it while starting from the weights found so far."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9cJA1OhcYpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf.final_fit(x_train, y_train, x_test, y_test, retrain=False)\n",
        "result = clf.evaluate(x_test, y_test)\n",
        "print('The resulting accuracy is ' + str(result))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4OvgHD1cv_p",
        "colab_type": "text"
      },
      "source": [
        "Hurray, we are done training! Hopefully, we are happy with the results and we can export the model for other uses. Note that this is an AutoKeras model and can not be saved as say a Keras model. This is due to the automated preprocessing steps which are not included in conventional ML software."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twO28j9tdET4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf.export_autokeras_model('automodel.h5')\n",
        "print('exporting done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwRRn99LdmCY",
        "colab_type": "text"
      },
      "source": [
        "As a last step, let's consult the confusion matrix to get some insight in our performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qpv_mXfdwC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "y_prediction = clf.predict(x_test)\n",
        "print('The confusion matrix is: ')\n",
        "print(str(confusion_matrix(y_test, y_prediction)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoayWV3Beu2B",
        "colab_type": "text"
      },
      "source": [
        "Further notes:\n",
        "we can invest the output of our search in our own defined folder: mnist_automodels\n",
        "In there we find a file for the models from every iteration. The best found model is specified in the file best_model.txt . In the log file we can view the added operations in every iteration including the father model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhhoPRMUd2rT",
        "colab_type": "text"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtrxNS6Kd4eG",
        "colab_type": "text"
      },
      "source": [
        "To visualize our attained model, some specific software  is used as recommended by the AutoKeras authors. First, install the requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8nmYvNbeJIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! sudo apt-get install libcairo2-dev\n",
        "! sudo apt-get install libpango1.0-dev"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6voErRVeLlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! sudo apt install curl\n",
        "! curl -O https://graphviz.gitlab.io/pub/graphviz/stable/SOURCES/graphviz.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLMTrJKnePRC",
        "colab_type": "text"
      },
      "source": [
        "Install Graphviz:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbqLWcdveRLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! tar -xzf graphviz.tar.gz\n",
        "! dir\n",
        "! graphviz-2.40.1/configure\n",
        "! make\n",
        "! sudo make install\n",
        "! pip3 install graphviz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkTsBuUEeTfi",
        "colab_type": "text"
      },
      "source": [
        "Import the packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0aetjsCeVFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from graphviz import Digraph\n",
        "\n",
        "from autokeras.utils import pickle_from_file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fapE0lJFegaQ",
        "colab_type": "text"
      },
      "source": [
        "And we define the needed functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_jJKmRZeZge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_pdf(graph, path):\n",
        "    dot = Digraph(comment='The Round Table')\n",
        "\n",
        "    for index, node in enumerate(graph.node_list):\n",
        "        dot.node(str(index), str(node.shape))\n",
        "\n",
        "    for u in range(graph.n_nodes):\n",
        "        for v, layer_id in graph.adj_list[u]:\n",
        "            dot.edge(str(u), str(v), str(graph.layer_list[layer_id]))\n",
        "\n",
        "    dot.render(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1plEyOT5ejYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize(path):\n",
        "    cnn_module = pickle_from_file(os.path.join(path, 'module'))\n",
        "    cnn_module.searcher.path = path\n",
        "    for item in cnn_module.searcher.history:\n",
        "        model_id = item['model_id']\n",
        "        graph = cnn_module.searcher.load_model_by_id(model_id)\n",
        "        to_pdf(graph, os.path.join(path, str(model_id)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvm8aaQSeqTg",
        "colab_type": "text"
      },
      "source": [
        "Doing this, the visualization of our model will be saved as a pdf file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-N5AbFyelkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize('mnist_automodels')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWLX5GgLX3ON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}