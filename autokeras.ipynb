{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autokeras.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7F2IGaPZF8o",
        "colab_type": "text"
      },
      "source": [
        "# AutoKeras Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnVpu9lqZUvH",
        "colab_type": "text"
      },
      "source": [
        "In this tutorial, the use of AutoKeras will be explained for an example dataset: MNIST. Ofcourse, all the functionalities directly apply on real-life data. Before you start, it is important to note that for the current AutoKeras version 0.4, a Linux system working with Python 3.6 is needed for this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qY52fgLjZONg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! python --version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZM8NZ8xzZ59-",
        "colab_type": "text"
      },
      "source": [
        "For the setup, we will import the needed packages and the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJtZq5SzaBJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip3 install autokeras --no-cache-dir  # install the autokeras package: this is quite big and we try to avoid memory issues I got in the past"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vlUl8RtaMaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import autokeras   # as a test\n",
        "from autokeras.image.image_supervised import load_image_dataset\n",
        "import cv2\n",
        "import sklearn\n",
        "from autokeras.image.image_supervised import ImageClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNXO9hvnaQld",
        "colab_type": "text"
      },
      "source": [
        "# The MNIST example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbPMzgSlaSzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from autokeras.image.image_supervised import ImageClassifier\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()    # download the data\n",
        "x_train = x_train.reshape(x_train.shape + (1,))\n",
        "x_test = x_test.reshape(x_test.shape + (1,))         # A 4D vector is expected"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWixLBeladv7",
        "colab_type": "text"
      },
      "source": [
        "Lets initiate our classifier! We will take one hour of training which should normally be enough for 1GPU to get a good result. Of course for MNIST this works very well but for real-world data, you might need to search longer. As you will see, the logs printed in verbose mode will allow you to follow the process quite nicely. At first, the API will receive the call and preprocesses the dataset. From then on your CPU will be looking for new models based on network morphism guided by Bayesian optimization. Meanwhile, your GPU will be training those in order to find the best performing one. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nqBSh8P7vQG",
        "colab_type": "text"
      },
      "source": [
        "NOTE THAT IF YOU ARE NOT RUNNING ON A GPU, THE SEARCH TIME WILL BE TOO SHORT TO FIND A MODEL (in Google collab you can change this in the settings)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXl-GwMmad3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = ImageClassifier(path=\"mnist_automodels/\", verbose=True)    # declare your classifier, with a path to save it's found models\n",
        "clf.fit(x_train, y_train, time_limit=1 * 60 * 60)    # we will be training for one hour"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQMc5T2Ubv2E",
        "colab_type": "text"
      },
      "source": [
        "Once we reached our time limit or the training converged, we are ready to train our best found model further for best performance. Since it will now include validation data in its training set, we can choose to restart training the weights from scratch with this little more data. This takes a long time, so in this example we will just keep training it while starting from the weights found so far."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9cJA1OhcYpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf.final_fit(x_train, y_train, x_test, y_test, retrain=False)\n",
        "result = clf.evaluate(x_test, y_test)\n",
        "print('The resulting accuracy is ' + str(result))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4OvgHD1cv_p",
        "colab_type": "text"
      },
      "source": [
        "Hurray, we are done training! Hopefully, we are happy with the results and we can export the model for other uses. Note that this is an AutoKeras model and can not be saved as say a Keras model. This is due to the automated preprocessing steps which are not included in conventional ML software."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twO28j9tdET4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf.export_autokeras_model('automodel.h5')\n",
        "print('exporting done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwRRn99LdmCY",
        "colab_type": "text"
      },
      "source": [
        "As a last step, let's consult the confusion matrix to get some insight in our performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qpv_mXfdwC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "y_prediction = clf.predict(x_test)\n",
        "print('The confusion matrix is: ')\n",
        "print(str(confusion_matrix(y_test, y_prediction)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j0Y-SjFsxwE",
        "colab_type": "text"
      },
      "source": [
        "# Visualization\n",
        "To visualize the generated model to a pdf file, you can use the visualize.py file as included in my github repo:\n",
        "https://github.com/jasperdewitte/AutoKeras-Tutorial"
      ]
    }
  ]
}